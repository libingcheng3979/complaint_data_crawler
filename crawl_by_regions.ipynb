{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba700f8-4515-4835-bf93-060c141af7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "import os\n",
    "import urllib3\n",
    "\n",
    "# 禁用SSL警告\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "# 配置日志\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('crawler.log', encoding='utf-8'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "def create_session():\n",
    "    \"\"\"创建带有重试机制的会话\"\"\"\n",
    "    session = requests.Session()\n",
    "    retry_strategy = Retry(\n",
    "        total=10,  # 最大重试次数\n",
    "        backoff_factor=2,  # 重试间隔\n",
    "        status_forcelist=[500, 502, 503, 504],  # 需要重试的HTTP状态码\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "    session.mount(\"http://\", adapter)\n",
    "    session.mount(\"https://\", adapter)\n",
    "    session.verify = False  # 禁用SSL验证\n",
    "    return session\n",
    "\n",
    "def timestamp_to_date(timestamp):\n",
    "    return datetime.fromtimestamp(timestamp).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "def get_last_processed_page():\n",
    "    \"\"\"获取上次处理到的页码\"\"\"\n",
    "    try:\n",
    "        if os.path.exists('checkpoint.json'):\n",
    "            with open('checkpoint.json', 'r') as f:\n",
    "                return json.load(f)['last_page']\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"读取断点文件失败: {e}\")\n",
    "    return 1\n",
    "\n",
    "def save_checkpoint(page):\n",
    "    \"\"\"保存当前处理的页码\"\"\"\n",
    "    try:\n",
    "        with open('checkpoint.json', 'w') as f:\n",
    "            json.dump({'last_page': page}, f)\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"保存断点失败: {e}\")\n",
    "\n",
    "def fetch_data():\n",
    "    # 设置请求URL和headers\n",
    "    url = 'https://api1.liuyan.cjn.cn/messageboard/internetUserInterface/selectThreadsByGroup'\n",
    "    headers = {\n",
    "        'Accept': 'application/json, text/plain, */*',\n",
    "        'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8,en-GB;q=0.7,en-US;q=0.6',\n",
    "        'Content-Type': 'application/x-www-form-urlencoded',\n",
    "        'Origin': 'https://liuyan.cjn.cn',\n",
    "        'Referer': 'https://liuyan.cjn.cn/',\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36 Edg/131.0.0.0',\n",
    "        'sec-ch-ua': '\"Microsoft Edge\";v=\"131\", \"Chromium\";v=\"131\", \"Not_A Brand\";v=\"24\"',\n",
    "        'sec-ch-ua-mobile': '?0',\n",
    "        'sec-ch-ua-platform': '\"Windows\"'\n",
    "    }\n",
    "\n",
    "    session = create_session()\n",
    "    all_data = []\n",
    "    records_count = 0\n",
    "    \n",
    "    try:\n",
    "        # 获取起始页码（断点续传）\n",
    "        start_page = get_last_processed_page()\n",
    "        \n",
    "        # 首先获取总数据量\n",
    "        data = {\n",
    "            'pageSize': '100',\n",
    "            'pageNum': '1',\n",
    "            'fid': '6',#修改\n",
    "            'handleState': '',\n",
    "            'threadState': ''\n",
    "        }\n",
    "        \n",
    "        response = session.post(url, headers=headers, data=data, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        first_page = response.json()\n",
    "        total_records = first_page['total']\n",
    "        total_pages = (total_records + 99) // 100\n",
    "        \n",
    "        logging.info(f\"总记录数: {total_records}, 总页数: {total_pages}, 从第 {start_page} 页继续\")\n",
    "        \n",
    "        # 创建进度条\n",
    "        with tqdm(total=total_records, initial=(start_page-1)*100) as pbar:\n",
    "            for page in range(start_page, total_pages + 1):\n",
    "                retry_count = 0\n",
    "                max_retries = 10\n",
    "                \n",
    "                while retry_count < max_retries:\n",
    "                    try:\n",
    "                        data['pageNum'] = str(page)\n",
    "                        response = session.post(url, headers=headers, data=data, timeout=30)\n",
    "                        response.raise_for_status()\n",
    "                        json_data = response.json()\n",
    "                        \n",
    "                        if 'rows' not in json_data:\n",
    "                            raise ValueError(f\"数据格式错误: {json_data}\")\n",
    "                        \n",
    "                        # 获取forum信息\n",
    "                        forum_info = json_data.get('other', {}).get('forum', {})\n",
    "                        \n",
    "                        # 处理每条记录\n",
    "                        for row in json_data['rows']:\n",
    "                            if row.get('dateline'):\n",
    "                                row['dateline'] = timestamp_to_date(row['dateline'])\n",
    "                            \n",
    "                            for key, value in forum_info.items():\n",
    "                                row[f'forum_{key}'] = value\n",
    "                            \n",
    "                            all_data.append(row)\n",
    "                            records_count += 1\n",
    "                            pbar.update(1)\n",
    "                        \n",
    "                        # 每500条数据保存一次\n",
    "                        if records_count % 500 == 0:\n",
    "                            df = pd.DataFrame(all_data)\n",
    "                            df.to_csv('6江岸区.csv', index=False, encoding='utf-8-sig', \n",
    "                                    mode='a', header=(records_count==500))\n",
    "                            all_data = []\n",
    "                        \n",
    "                        # 保存断点\n",
    "                        save_checkpoint(page)\n",
    "                        \n",
    "                        # 随机延迟\n",
    "                        delay_time = random.uniform(12, 15)\n",
    "                        time.sleep(delay_time)\n",
    "                        \n",
    "                        break  # 成功获取数据，跳出重试循环\n",
    "                        \n",
    "                    except requests.exceptions.RequestException as e:\n",
    "                        retry_count += 1\n",
    "                        if retry_count == max_retries:\n",
    "                            logging.error(f\"第{page}页请求失败，已达到最大重试次数: {str(e)}\")\n",
    "                            continue\n",
    "                        wait_time = 2 ** retry_count  # 指数退避\n",
    "                        logging.warning(f\"第{page}页请求失败，{wait_time}秒后重试: {str(e)}\")\n",
    "                        time.sleep(wait_time)\n",
    "                    except Exception as e:\n",
    "                        logging.error(f\"处理第{page}页时发生错误: {str(e)}\")\n",
    "                        break\n",
    "        \n",
    "        # 保存剩余数据\n",
    "        if all_data:\n",
    "            df = pd.DataFrame(all_data)\n",
    "            df.to_csv('6江岸区.csv', index=False, encoding='utf-8-sig', mode='a', header=False)\n",
    "            \n",
    "    except Exception as e:\n",
    "        logging.error(f\"发生致命错误: {str(e)}\")\n",
    "    finally:\n",
    "        logging.info(f\"爬取完成！共获取 {records_count} 条记录\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743f6699-6f12-4cc5-85d5-f7925b07adf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('6江岸区.csv')\n",
    "\n",
    "total_rows = len(df)\n",
    "print(f\"文件总行数：{total_rows}\")\n",
    "\n",
    "unique_rows = len(df.drop_duplicates())\n",
    "print(f\"去重后行数：{unique_rows}\")\n",
    "\n",
    "duplicate_rows = total_rows - unique_rows\n",
    "print(f\"重复行数：{duplicate_rows}\")\n",
    "\n",
    "if duplicate_rows > 0:\n",
    "    duplicates = df[df.duplicated(keep=False)]\n",
    "    print(\"\\n重复的数据如下：\")\n",
    "    print(duplicates)\n",
    "    \n",
    "    response = input(\"\\n是否需要保存去重后的文件？(y/n): \")\n",
    "    if response.lower() == 'y':\n",
    "        df_unique = df.drop_duplicates()\n",
    "        df_unique.to_csv('6江岸区_去重后.csv', index=False)\n",
    "        print(\"去重后的文件已保存为：6江岸区_去重后.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DA",
   "language": "python",
   "name": "da"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
